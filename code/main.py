import numpy as np
import math
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
from scipy.interpolate import griddata
import pandas as pd

threeblob_X_file = '../data/threeblob_X.npy'
threeblob_label_file = '../data/threeblob_label.npy'
pendigits_X_file = '../data/pendigits_X.npy'
pendigits_y_file = '../data/pendigits_y.npy'
speech_X_file = '../data/speech_X.npy'
speech_y_file = '../data/speech_y.npy'


def knn_outlier_detection(X: np.ndarray, k: int) -> tuple[np.ndarray, np.ndarray]:
    """
    ä½¿ç”¨ kNN ç®—æ³•è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚baselineã€‚

    Parameters:
    -----------
    X : np.ndarray, shape (n_samples, n_features)
        è¾“å…¥çš„æ•°æ®çŸ©é˜µã€‚
    k : int
        æœ€è¿‘é‚»çš„æ•°é‡ï¼ˆkå€¼ï¼‰ã€‚

    Returns:
    --------
    scores : np.ndarray, shape (n_samples,)
        æ¯ä¸ªæ ·æœ¬çš„å¼‚å¸¸åˆ†æ•°ï¼ˆåˆ°ç¬¬kä¸ªæœ€è¿‘é‚»çš„è·ç¦»ï¼‰ï¼Œåˆ†æ•°è¶Šé«˜è¶Šå¯èƒ½æ˜¯å¼‚å¸¸ã€‚
    ranks : np.ndarray, shape (n_samples,)
        æŒ‰å¼‚å¸¸åˆ†æ•°ä»é«˜åˆ°ä½æ’åºçš„æ ·æœ¬ç´¢å¼•ã€‚

    Example:
    --------
    scores, ranks = knn_outlier_detection(X, k=20)
    """
    n_samples = X.shape[0]

    # ä½¿ç”¨ sklearn çš„ NearestNeighbors æ‰¾åˆ°æ¯ä¸ªç‚¹çš„ k ä¸ªæœ€è¿‘é‚»
    # æ³¨æ„ï¼šå®ƒä¼šåŒ…å«è‡ªå·±ï¼ˆè·ç¦»ä¸º0ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰¾ k+1 ä¸ªé‚»å±…ï¼Œç„¶åå–ç¬¬2åˆ°ç¬¬k+1ä¸ª
    n_neighbors = k + 1
    nn = NearestNeighbors(n_neighbors=n_neighbors)
    nn.fit(X)

    # distances.shape = (n_samples, k+1), ç¬¬ä¸€åˆ—æ˜¯åˆ°è‡ªèº«çš„è·ç¦»ï¼ˆ0ï¼‰
    distances, _ = nn.kneighbors(X)

    # å–ç¬¬ k ä¸ªæœ€è¿‘é‚»çš„è·ç¦»ï¼ˆå³ç´¢å¼•ä¸º k çš„åˆ—ï¼Œå› ä¸ºç´¢å¼•ä»0å¼€å§‹ï¼‰
    # æ³¨æ„ï¼šdistances[:, 0] æ˜¯åˆ°è‡ªèº«çš„è·ç¦»ï¼ˆ0ï¼‰ï¼Œdistances[:, 1] æ˜¯åˆ°ç¬¬1ä¸ªé‚»å±…ï¼Œ... distances[:, k] æ˜¯åˆ°ç¬¬kä¸ªé‚»å±…
    kth_distances = distances[:, k]  # å¼‚å¸¸åˆ†æ•°ï¼šè¶Šå¤§è¶Šå¼‚å¸¸

    # æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½æ’åºï¼ˆå¼‚å¸¸ä¼˜å…ˆï¼‰
    ranks = np.argsort(-kth_distances)  # è´Ÿå·å®ç°é™åºæ’åº

    return kth_distances, ranks

def load_data():
    """
    åŠ è½½ç‰¹å¾æ•°æ®å’Œæ ‡ç­¾æ•°æ®
    """
    try:
        threeblob_X = np.load(threeblob_X_file)
        threeblob_y = np.load(threeblob_label_file)
        pendigits_X = np.load(pendigits_X_file)
        pendigits_y = np.load(pendigits_y_file)
        speech_X = np.load(speech_X_file)
        speech_y = np.load(speech_y_file)
        print("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
        print(f"threeblob ç‰¹å¾æ•°æ® X çš„å½¢çŠ¶: {threeblob_X.shape}")
        print(f"threeblob æ ‡ç­¾æ•°æ® y çš„å½¢çŠ¶: {threeblob_y.shape}")
        print(f"threeblob æ ‡ç­¾åˆ†å¸ƒ: æ­£å¸¸ç‚¹ (0) = {np.sum(threeblob_y == 0)}, å¼‚å¸¸ç‚¹ (1) = {np.sum(threeblob_y == 1)}")
        print(f"pendigits ç‰¹å¾æ•°æ® X çš„å½¢çŠ¶: {pendigits_X.shape}")
        print(f"pendigits æ ‡ç­¾æ•°æ® y çš„å½¢çŠ¶: {pendigits_y.shape}")
        print(f"pendigits æ ‡ç­¾åˆ†å¸ƒ: æ­£å¸¸ç‚¹ (0) = {np.sum(pendigits_y == 0)}, å¼‚å¸¸ç‚¹ (1) = {np.sum(pendigits_y == 1)}")
        print(f"speech ç‰¹å¾æ•°æ® X çš„å½¢çŠ¶: {speech_X.shape}")
        print(f"speech ç‰¹å¾æ•°æ® y çš„å½¢çŠ¶: {speech_y.shape}")
        print(f"speech æ ‡ç­¾åˆ†å¸ƒ: æ­£å¸¸ç‚¹ (0) = {np.sum(speech_y == 0)}, å¼‚å¸¸ç‚¹ (1) = {np.sum(speech_y == 1)}")
        return threeblob_X, threeblob_y, pendigits_X, pendigits_y, speech_X, speech_y
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {e}")
        print("è¯·ç¡®ä¿ threeblob_X.npy å’Œ threeblob_labels.npy åœ¨å½“å‰ç›®å½•ä¸‹ã€‚")
        return None, None, None, None
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None, None, None, None

def get_result(X, y, scores, ranks, filepath=None, title=None):
    """
    è®¡ç®— ROC AUC å’Œ P@Nï¼Œå¹¶å¯é€‰åœ°ç»˜åˆ¶é«˜è´¨é‡å†³ç­–è¾¹ç•Œå›¾ï¼ˆè®ºæ–‡é£æ ¼ï¼‰
    ä½¿ç”¨æ’å€¼ç”Ÿæˆå¹³æ»‘çš„å¼‚å¸¸åˆ†æ•°çƒ­åŠ›å›¾ + ç­‰é«˜çº¿
    """
    from sklearn.metrics import roc_auc_score

    # ---------- 1. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ ----------
    roc_auc = roc_auc_score(y, scores)

    N = np.sum(y == 1)
    if N == 0 or N == len(y):
        raise ValueError("æ•°æ®é›†éœ€è¦åŒ…å«æ­£å¸¸å’Œå¼‚å¸¸æ ·æœ¬ï¼Œæ‰èƒ½è®¡ç®— P@Nã€‚")

    top_N_indices = ranks[:N]
    p_at_n = np.mean(y[top_N_indices] == 1)
    errno = int(N * p_at_n)

    # ---------- 2. é«˜è´¨é‡å¯è§†åŒ– ----------
    if filepath is not None and title is not None:
        title = title + f" ({errno} errors)"
        plt.figure(figsize=(8, 6), dpi=150)
        ax = plt.gca()

        # ---- åˆ›å»ºç½‘æ ¼ç”¨äºæ’å€¼ ----
        margin = 0.3
        x_min, x_max = X[:, 0].min() - margin, X[:, 0].max() + margin
        y_min, y_max = X[:, 1].min() - margin, X[:, 1].max() + margin

        nx, ny = 200, 200
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),
                             np.linspace(y_min, y_max, ny))

        # ---- æ’å€¼å¼‚å¸¸åˆ†æ•°åˆ°ç½‘æ ¼ ----
        grid_scores = griddata(
            points=X,
            values=scores,
            xi=(xx, yy),
            method='cubic',  # å¯é€‰ 'linear', 'nearest'
            fill_value=np.nan
        )

        # ---- ç»˜åˆ¶çƒ­åŠ›å›¾ï¼ˆå¼‚å¸¸åˆ†æ•°ï¼‰ ----
        # ä½¿ç”¨æŸ”å’Œçš„ colormapï¼Œçªå‡ºå¼‚å¸¸åŒºåŸŸ
        cmap = plt.cm.YlOrRd  # Yellow -> Orange -> Red
        contourf = ax.contourf(xx, yy, grid_scores, levels=20, cmap=cmap, alpha=0.6, zorder=1)

        # ---- ç»˜åˆ¶ç­‰é«˜çº¿ ----
        contour = ax.contour(xx, yy, grid_scores, levels=10, colors='orange', alpha=0.8, linewidths=1.2, zorder=2)

        # ---- ç»˜åˆ¶æ•°æ®ç‚¹ ----
        # æ­£å¸¸ç‚¹ï¼šç™½è‰²å¸¦é»‘è¾¹
        inliers = X[y == 0]
        ax.scatter(inliers[:, 0], inliers[:, 1],
                   c='white', edgecolors='black', s=50, alpha=0.9, zorder=3, label='Inliers')

        # å¼‚å¸¸ç‚¹ï¼šé»‘è‰²å®å¿ƒ
        outliers = X[y == 1]
        ax.scatter(outliers[:, 0], outliers[:, 1],
                   c='black', s=50, alpha=0.9, zorder=3, label='Outliers')

        # ---- ç¾åŒ–æ ·å¼ ----
        ax.set_title(title, fontsize=14, pad=20)
        ax.set_xlabel('Feature 1', fontsize=12)
        ax.set_ylabel('Feature 2', fontsize=12)

        # å»æ‰ä¸Š/å³è¾¹æ¡†
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_linewidth(0.5)
        ax.spines['bottom'].set_linewidth(0.5)

        # åæ ‡è½´åˆ»åº¦
        ax.tick_params(axis='both', which='major', labelsize=10, width=0.5, length=3)

        # å›¾ä¾‹
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(handles, labels, loc='upper right', fontsize=10, frameon=True, fancybox=False, edgecolor='black', framealpha=0.9)

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜ä¸ºé«˜åˆ†è¾¨ç‡ PNG æˆ– PDFï¼ˆæ¨èè®ºæ–‡ç”¨ PDFï¼‰
        plt.savefig(filepath, dpi=300, bbox_inches='tight', pad_inches=0.1)
        plt.close()

        print(f"âœ… è®ºæ–‡çº§å›¾åƒå·²ä¿å­˜è‡³: {filepath}")

    return roc_auc, p_at_n


if __name__ == "__main__":
    # tbæ˜¯äººå·¥ç”Ÿæˆçš„æ•°æ®ï¼Œpdæ˜¯çœŸå®æ‰‹å†™å›¾åƒæ•°æ®ï¼Œspæ˜¯çœŸå®æ¼”è®²æ•°æ®
    tb_X, tb_y, pd_X, pd_y, sp_X, sp_y = load_data()
    tb_scores, tb_ranks = knn_outlier_detection(tb_X, int(math.sqrt(tb_X.shape[0])))
    tb_roc_auc, tb_p_at_n = get_result(tb_X, tb_y, tb_scores, tb_ranks, "./output/tb_knn", "knn outcome on threeblob data")
    pd_scores, pd_ranks = knn_outlier_detection(pd_X, int(math.sqrt(tb_X.shape[0])))
    pd_roc_auc, pd_p_at_n = get_result(pd_X, pd_y, pd_scores, pd_ranks)
    sp_scores, sp_ranks = knn_outlier_detection(sp_X, int(math.sqrt(sp_X.shape[0])))
    sp_roc_auc, sp_p_at_n = get_result(sp_X, sp_y, sp_scores, sp_ranks)

    # ä¸‹é¢æ˜¯ç»Ÿè®¡ç»“æœè¡¨æ ¼
    models = {}
    knn_results = {}
    knn_results["threeblob"] = {"roc_auc": tb_roc_auc, "p_at_n": tb_p_at_n};
    knn_results["speech"] = {"roc_auc": sp_roc_auc, "p_at_n": sp_p_at_n};
    knn_results["pendigits"] = {"roc_auc": pd_roc_auc, "p_at_n": pd_p_at_n};
    models['knn'] = knn_results

    # å®šä¹‰æ•°æ®é›†åç§°å’Œå¯¹åº”çš„æ•°æ®
    datasets = {
        'threeblob': (tb_X, tb_y),
        'pendigits': (pd_X, pd_y),
        'speech': (sp_X, sp_y)
    }
    # === æ„å»º ROC-AUC è¡¨æ ¼ ===
    roc_df = pd.DataFrame({
        model_name: [results[ds]['roc_auc'] for ds in datasets.keys()]
        for model_name, results in models.items()
    }, index=list(datasets.keys())).T  # è½¬ç½®ï¼šè¡Œæ˜¯æ¨¡å‹ï¼Œåˆ—æ˜¯æ•°æ®é›†
    roc_df.index.name = "Model"
    roc_df.columns.name = "Dataset"

    # === æ„å»º P@N è¡¨æ ¼ ===
    p_at_n_df = pd.DataFrame({
        model_name: [results[ds]['p_at_n'] for ds in datasets.keys()]
        for model_name, results in models.items()
    }, index=list(datasets.keys())).T
    p_at_n_df.index.name = "Model"
    p_at_n_df.columns.name = "Dataset"

    # === æ‰“å°è¡¨æ ¼ ===
    print("\n" + "=" * 50)
    print("ğŸ“Š ROC-AUC è¡¨æ ¼")
    print("=" * 50)
    print(roc_df.round(3))

    print("\n" + "=" * 50)
    print("ğŸ“Š Precision @ N è¡¨æ ¼")
    print("=" * 50)
    print(p_at_n_df.round(3))

    roc_df.round(3).to_csv("./output/roc_auc.csv")
    p_at_n_df.round(3).to_csv("./output/p_at_n.csv")

